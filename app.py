import streamlit as st
import json
from datetime import datetime
import os
from copy import deepcopy
import time

from modules.configs import FAISS_PATH
from modules.extractings import PDFExtractor, HTMLExtractor, DOCXExtractor, TXTExtractor
from modules.chunkings import SemanticChunk
from modules.embeddings import HFEmbedding
from modules.storings import FAISSDatabase

 # Initialize chunks list in session state
if "chunks" not in st.session_state:
    st.session_state.chunks = []

# Initialize delete state
if "delete_index" not in st.session_state:
    st.session_state.delete_index = None

if "updated_rag" not in st.session_state:
    st.session_state.updated_rag = False

def load_chat_history(folder_path="database/chats"):
    try:
        all_chats = {}
        for file in os.listdir(folder_path):
            if file.endswith('.json'):
                student_id = file.replace('.json', '')
                with open(os.path.join(folder_path, file), 'r', encoding='utf-8') as f:
                    all_chats[student_id] = json.load(f)
        return all_chats
    except FileNotFoundError:
        print("File not found!")
        return {}
    except Exception as e:
        print(e)
        return {}

def display_chat_messages(messages):
    # Create a container with scrollbar
    
    for msg in messages:
        if msg["type"].lower() == "user":
            col1, col2 = st.columns([0.7, 0.3])
            with col1:
                st.write("ðŸ‘¤ User:", msg["text"])
            with col2:
                st.write(msg["chat_at"])
        else:
            col1, col2 = st.columns([0.7, 0.3])
            with col1:
                st.write("ðŸ¤– Server:", msg["text"])
            with col2:
                st.write(msg["chat_at"])
    

def filter_chats_by_date(chat_data, start_date, end_date):
    filtered_chats = {}
    for chat_id, chat_info in chat_data.items():
        chat_date = datetime.strptime(chat_info['createdAt'], "%Y-%m-%d %H:%M:%S")
        if start_date <= chat_date.date() <= end_date:
            filtered_chats[chat_id] = chat_info
    return filtered_chats

def reset_state():
    st.session_state.chunks = []
    st.session_state.delete_index = None
    st.session_state.updated_rag = True

def main():
    st.title("Há»‡ thá»‘ng quáº£n lÃ½ Chatbot")
    
    page = st.sidebar.selectbox("Chá»n 1 cÃ¡i", 
                               ["Lá»‹ch sá»­ chat", "Cáº­p nháº­t kiáº¿n thá»©c"])
    
    if page == "Lá»‹ch sá»­ chat":
        st.header("TÃ¬m kiáº¿m cuá»™c trÃ² chuyá»‡n")
        
        chat_history = load_chat_history()
        
        if chat_history:
            reset_state()
            student_list = ["Lá»±a chon mÃ£ sinh viÃªn"] + sorted(list(chat_history.keys()))
            selected_student = st.selectbox("MÃ£ sinh viÃªn", options=student_list)
            
            if selected_student != "Lá»±a chon mÃ£ sinh viÃªn":
                col1, col2 = st.columns(2)
                with col1:
                    start_date = st.date_input("Tá»« ngÃ y", format="DD/MM/YYYY")
                with col2:
                    end_date = st.date_input("Äáº¿n ngÃ y", format="DD/MM/YYYY")
                
                st.subheader(f"Lá»‹ch sá»­ trÃ² chuyá»‡n: {selected_student}")
                filtered_chats = filter_chats_by_date(chat_history[selected_student], start_date, end_date)
                
                if filtered_chats:
                    sorted_chats = sorted(filtered_chats.items(), 
                                        key=lambda x: datetime.strptime(x[1]['createdAt'], "%Y-%m-%d %H:%M:%S"),
                                        reverse=True)
                    
                    for chat_id, chat_data in sorted_chats:
                        create_date = chat_data['createdAt'].split(" ")[0]
                        with st.expander(f"ID: {chat_id} - NgÃ y táº¡o: {create_date}"):
                            if chat_data['messages']:
                                display_chat_messages(chat_data['messages'])
                            else:
                                st.info("KhÃ´ng cÃ³ cuá»™c trÃ² chuyá»‡n nÃ o.")
                else:
                    st.info("KhÃ´ng tÃ¬m tháº¥y cuá»™c trÃ² chuyá»‡n trong khoáº£ng thá»i gian nÃ y.")
            else:
                st.info("Chá»n mÃ£ sinh Ä‘á»ƒ tÃ¬m kiáº¿m cuá»™c trÃ² chuyá»‡n.")
        else:
            st.warning("KhÃ´ng cÃ³ lá»‹ch sá»­ trÃ² chuyá»‡n.")

    elif page == "Cáº­p nháº­t kiáº¿n thá»©c":
        st.header("Cáº­p nháº­t kiáº¿n thá»©c cho Chatbot")

        uploaded_file = st.file_uploader("Táº£i lÃªn tá»‡p", type=['txt', 'pdf', 'html', 'docx'])

        if uploaded_file:            
            try:
                # File handling logic
                if uploaded_file.name.endswith('.docx'):
                    with open("temp.docx", "wb") as f:
                        f.write(uploaded_file.getbuffer())
                    docx_extractor = DOCXExtractor()
                    doc = docx_extractor.load("temp.docx")
                    os.remove("temp.docx")
                elif uploaded_file.name.endswith('.pdf'):
                    with open("temp.pdf", "wb") as f:
                        f.write(uploaded_file.getbuffer())
                    pdf_extractor = PDFExtractor()
                    doc = pdf_extractor.load("temp.pdf")
                    os.remove("temp.pdf")
                elif uploaded_file.name.endswith('.html'):
                    with open("temp.html", "wb") as f:
                        f.write(uploaded_file.getbuffer())
                    html_extractor = HTMLExtractor()
                    doc = html_extractor.load("temp.html")
                    os.remove("temp.html")
                elif uploaded_file.name.endswith('.txt'):
                    with open("temp.txt", "wb") as f:
                        f.write(uploaded_file.getbuffer())
                    txt_extractor = TXTExtractor()
                    doc = txt_extractor.load("temp.txt")
                    os.remove("temp.txt")

                preview_text = st.text_area(label="Xem trÆ°á»›c ná»™i dung", value=doc.page_content, height=200)

                if st.button("Chia nhá» dá»¯ liá»‡u"):
                    doc.page_content = preview_text
                    embedding = HFEmbedding()
                    chunker = SemanticChunk(embedding_model=embedding)
                    chunks = chunker.chunking([doc])
                    st.session_state.chunks = deepcopy(chunks)

                # Display and manage chunks
                if st.session_state.chunks:
                    for i in range(len(st.session_state.chunks)):
                        col1, col2 = st.columns([9, 1])
                        with col1:
                            st.session_state.chunks[i].page_content = st.text_area(
                                label=f"Máº©u {i}",
                                value=st.session_state.chunks[i].page_content,
                                height=200,
                                key=f"chunk_{i}"
                            )
                        with col2:
                            if st.button("XÃ³a", key=f"delete_{i}"):
                                st.session_state.delete_index = i
                                break

                    # Handle deletion
                    if st.session_state.delete_index is not None:
                        st.session_state.chunks.pop(st.session_state.delete_index)
                        st.session_state.delete_index = None
                        st.rerun()

                    # Add new chunk
                    if st.button("ThÃªm"):
                        new_chunk = deepcopy(st.session_state.chunks[-1]) if st.session_state.chunks else SemanticChunk()
                        new_chunk.page_content = ""
                        st.session_state.chunks.append(new_chunk)
                        st.rerun()

                    # Save chunks
                    if st.button("LÆ°u"):
                        try:
                            vector_store = FAISSDatabase(HFEmbedding(), FAISS_PATH)
                            db = vector_store.db_get()
                            vector_store.db_add(st.session_state.chunks)
                            reset_state()
                            st.rerun()
                        except Exception as e:
                            st.error(f"Lá»—i khi lÆ°u tá»‡p JSON: {str(e)}")
                
                if st.session_state.updated_rag:
                    st.success("Cáº­p nháº­t kiáº¿n thá»©c thÃ nh cÃ´ng!")
                    time.sleep(3)
                    st.session_state.updated_rag = False

            except Exception as e:
                st.error(f"Gáº·p lá»—i khi xá»­ lÃ½ file: {str(e)}")

if __name__ == "__main__":
    main()
